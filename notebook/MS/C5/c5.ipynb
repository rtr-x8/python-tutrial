{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "簡単に言うと、機械学習モデルは、x (特徴量) から y (ラベル) を計算する関数 f(x)=y です。\n",
    "\n",
    "ペンギンの種類を推測する時、嘴の長さ、深さ、足の長さ、体重の4つは特徴量であり、数学的には\n",
    "```\n",
    "x=[x1,x2,x3,x4]\n",
    "```\n",
    "のベクトルで表される。全部で3種類のペンギンがいると仮定すると、yは3つの確率値のベクトル\n",
    "```\n",
    "（y=[P(0), P(1), P(2)]）\n",
    "```\n",
    "となる。\n",
    "\n",
    "\n",
    "これをディープラーニングに入れるとどうなるか。\n",
    "\n",
    "各入力値のxごとにニューロンを含む入力そう、隠れ層、出力のクラスごとに出力層。（ペンギンの例だと、入力層は5つのニューロンを含み、出力層は3つのニューロンからなる）\n",
    "\n",
    "## ディープラーニングのトレーニング\n",
    "\n",
    "プロセスはエポックと呼ばれる複数の反復で構成される。  \n",
    "まず重み（w）とバイアス（b）にランダムな初期値を割り当てる。\n",
    "\n",
    "1. 既知のラベル値を持つデータの特徴量が入力層へ送信される。これらはバッチにグループ化される\n",
    "2. ニューロンで関数が適用され、次の層へ結果が渡される\n",
    "3. 予測が実際の値と比較され、予測値と実際の値の際の量（損失）が計算される\n",
    "4. 結果に基づいて重みとバイアスを修正する。これらの調整はネットワーク層のニューロンに逆伝播する。\n",
    "5. 次のエポックで修正された重みとバイアスの値を使用して、バッチトレーニングを繰り返す\n",
    "\n",
    "## 損失の計算\n",
    "\n",
    "ペンギンのタイプが3種類で、Aである時、期待する出力は`[1,0,0]`となる。実際が`[0.4,0.3,0.3]`である時、差が`[0.6,0.4,0.4]`である。  \n",
    "分散を集計すると0.18となる。\n",
    "\n",
    "## オプティマイザ\n",
    "\n",
    "入力から出力まで、モデル全体は入れ子になった関数であるため、図で示すことができる。　　\n",
    "また美文によって微分係数を計算でいる。\n",
    "\n",
    "モデル内の全ての変数・バイアスに対して傾きを係数より算出し、上昇になるように調整する。アルゴリズムにはSGD, ADADELTA. Adomなどがある\n",
    "\n",
    "## 学習りつ\n",
    "\n",
    "ハイパーパラメータ\n",
    "\n",
    "オプティマイザは重みとバイアスをどれだけ調整する必要があるか。\n",
    "\n",
    "調整の大きさは学習率によって制御される。低いと小さな調整が行われるが、多くのエポックが必要になる。高いと大きな調整が行われ、最小値を見逃す可能性が高い\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
